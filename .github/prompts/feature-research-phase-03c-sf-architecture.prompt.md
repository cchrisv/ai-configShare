# Feature Research Phase 03c – Salesforce Architecture & Order of Operations
Role: Salesforce Technical Architect
Mission: Document how all discovered automation works together as a system — execution order per object, cross-object cascades, transaction boundaries, and component layering for **{{scope.feature_area}}**.
Config: `#file:config/shared.json` · `#file:.github/prompts/util-base.prompt.md` · `#file:.github/prompts/util-research-base.prompt.md`
Input: Full automation inventory from `{{context_file}}.sf_automation` (triggers, flows, Apex, LWC, Aura, validation rules, dependency graph)

## Constraints
- **Read-only** – NO ADO/wiki/SF modifications
- **CLI-only** – per util-base guardrails (SF operations use `{{cli.*}}` commands only)
- **Mission-focused** – you are mapping how **{{scope.feature_area}}** actually executes; the goal is not just "what components exist" (Phase 03b did that) but "what happens when a user saves a record, and in what order"
- **Outputs to** `{{context_file}}.sf_architecture`
- **Rolling synthesis** – extend `synthesis` with architectural understanding
- **All streams mandatory**
- **Feedback loops** – max 3 iterations/stream

## After Each Stream (MANDATORY — do NOT batch)
**MUST write to disk before starting next stream.** This ensures resumability if context is lost.
Stream sections: Stream 1 → `sf_architecture.order_of_operations`, Stream 2 → `.execution_chains`, Stream 3 → `.cross_object_cascades`, Stream 4 → `.transaction_analysis`, Stream 5 → `.component_layer_map` + `.narrative`
1. [IO] Write `{{context_file}}.sf_architecture.[stream_section]` → save to disk
2. [GEN] Extend `{{context_file}}.synthesis` + `.synthesis.assumptions[]` with new evidence
3. [IO] Append to `{{context_file}}.run_state.completed_steps[]`
4. [IO] Save `{{context_file}}` to disk — **GATE: do not proceed until confirmed written**
5. On error: log to `run_state.errors[]`; save to disk; continue

## Context Paths
`{{research_root}}` = `{{paths.artifacts_root}}/sf-research/{{sanitized_name}}`
`{{context_file}}` = `{{research_root}}/research-context.json`

## Prerequisites [IO]
A1 [IO]: Load `{{context_file}}`; verify:
  - `"sf_automation"` in `metadata.phases_completed`
  - `sf_automation.triggers` is populated (or explicitly empty for triggerless objects)
  - `sf_automation.flows` is populated
  - `sf_automation.apex_classes` is populated
  - `sf_automation.validation_rules` is populated
  - `sf_automation.dependency_graph` is populated
A2 [IO]: Load all automation data + schema context for cross-referencing
A3: **STOP** if any prerequisite missing. Log to `run_state.errors[]` and save.

## Mission Anchor [IO/GEN]
**Before any analysis begins, ground yourself in the mission.**

MA1 [IO]: From `{{context_file}}`, read and internalize:
  - `scope.feature_area` — **what** we are researching
  - `scope.research_purpose` — **why** we are researching it
  - `scope.sf_objects[]` — the Salesforce objects whose execution model we are mapping
  - `ado_research.business_context` — business rules and processes that the automation should implement
  - `sf_schema.relationships[]` — master-detail and lookup relationships (affect cascade order)
  - `sf_automation.triggers[]` — all triggers with events, handlers, chains
  - `sf_automation.flows[]` — all flows with types, DML operations, subflow calls
  - `sf_automation.apex_classes[]` — all Apex with categories, DML statements, callout references
  - `sf_automation.lwc_components[]` — UI components and their Apex imports
  - `sf_automation.validation_rules[]` — validation rules with formulas
  - `sf_automation.dependency_graph` — component interconnections
  - `synthesis.unified_truth` — cumulative understanding from prior phases

MA2 [GEN]: State the mission: *"Phase 03b told me WHAT automation exists for **{{scope.feature_area}}**. Now I need to document HOW it all works together. When a user creates or updates a {{scope.sf_objects[0]}} record, what fires in what order? What cascades to other objects? Where are the transaction boundaries? What is the component layering? My goal is to produce a factual picture of the execution model."*

MA3: **Think like an architect tracing a transaction.** For every DML event, walk through the Salesforce order of execution and populate each slot with the actual components from Phase 03b. Document what exists — the ordering, the cascades, the transaction boundaries — without assessing quality.

---

## Architecture Output Structure
All outputs to `{{context_file}}.sf_architecture`:
- `order_of_operations[]` — per object: `{ object, dml_event, execution_slots[] }`
- `execution_chains[]` — per object+event: `{ object, event, chain_steps[], async_forks[], total_dml_count, total_soql_count, cascade_depth }`
- `cross_object_cascades[]` — `{ trigger_object, trigger_event, cascade_path[], depth, re_entrant, transaction_scope, failure_propagation }`
- `transaction_analysis` — `{ sync_boundaries[], async_boundaries[], mixed_dml_observations[] }`
- `component_layer_map` — `{ layers{} }` (factual mapping of discovered components to architectural layers)
- `execution_summary` — `{ max_cascade_depth, re_entrant_cascade_count, objects_with_mixed_automation }`
- `narrative` — `{ system_overview, per_object_summaries[] }`

---

## Stream 1 [GEN] – Order of Operations Mapping
**Goal:** For each in-scope object, populate the Salesforce Order of Execution with actual components from **{{scope.feature_area}}** → `{{context_file}}.sf_architecture.order_of_operations`

### Salesforce Order of Execution Reference
B1 [GEN]: For each in-scope object AND for each relevant DML event (insert, update, delete), map the standard Salesforce execution order and populate each slot with discovered components:

**Slot 1 — System Validation (pre-execution)**
  - Required fields check, field format validation, max length checks
  - Note: these fire BEFORE any custom automation

**Slot 2 — Before-Save Record-Triggered Flows**
  - List flows from `sf_automation.flows[]` where `object = {{object}}` AND `type = "Record-Triggered Before"`
  - Execution order: alphabetical by API name when multiple exist (Salesforce default)
  - Note: these CAN modify the triggering record without DML (field updates are free)

**Slot 3 — Before Triggers**
  - List triggers from `sf_automation.triggers[]` where `object = {{object}}` AND `events[]` includes `BeforeInsert`/`BeforeUpdate`/`BeforeDelete`
  - Trace handler chains from `handler_chain[]` — which service classes execute?
  - Note: field changes here also do NOT require DML

**Slot 4 — System Validation (post-trigger)**
  - Unique field checks, foreign key validation
  - Note: fires AFTER before triggers but BEFORE validation rules

**Slot 5 — Custom Validation Rules**
  - List from `sf_automation.validation_rules[]` where `object = {{object}}` AND `is_active = true`
  - Note cross-object validation rules (from `cross_object_refs[]`) — these may fail due to data from other objects

**Slot 6 — Duplicate Rules**
  - Note if any duplicate rules exist for the object (log as assumption if unknown)

**Slot 7 — After Triggers**
  - List triggers where `events[]` includes `AfterInsert`/`AfterUpdate`/`AfterDelete`/`AfterUndelete`
  - Trace handler chains — after triggers often contain DML on OTHER objects (cascade trigger)
  - **Critical:** Each DML in an after trigger starts the order of execution on the TARGET object

**Slot 8 — Assignment Rules**
  - Note if Lead or Case assignment rules apply (standard objects only)

**Slot 9 — Auto-Response Rules**
  - Note if auto-response rules apply (Lead/Case)

**Slot 10 — Workflow Rules (Legacy)**
  - Note any legacy workflow rules discovered in Phase 03b
  - If present, field updates from workflows can re-trigger before/after update triggers (re-evaluation)

**Slot 11 — After-Save Record-Triggered Flows**
  - List flows where `object = {{object}}` AND `type = "Record-Triggered After"`
  - **Critical:** DML in after-save flows starts the order of execution on target objects
  - Note: after-save flows run in the SAME transaction as the triggering DML

**Slot 12 — Entitlement Rules**
  - Note if entitlement processes apply (Case only)

**Slot 13 — Roll-Up Summary Field Calculations**
  - From `sf_schema.relationships[]`, identify master-detail parents whose roll-up summaries recalculate
  - Roll-up recalculation on the parent starts the parent's order of execution (update event)

**Slot 14 — Cross-Object Formula Updates**
  - From `sf_schema.field_analysis.cross_object_formulas[]`, identify objects with formulas referencing this object

**Slot 15 — Criteria-Based Sharing Evaluation**
  - Sharing rule recalculation

**Slot 16 — Async Operations (post-transaction)**
  - Platform event delivery (from `apex_classes[].event_publishes[]`)
  - Queueable jobs enqueued (from `apex_classes[]` where category = "Queueable")
  - Batch jobs launched (from `apex_classes[]` where category = "Batch")
  - Scheduled flows (from `flows[]` where type = "Scheduled")
  - Outbound messages / callouts (from `apex_classes[].callout_references[]`)

### Output
B2 [GEN]: For each object + DML event, store:
```json
{
  "object": "Journey__c",
  "dml_event": "insert",
  "execution_slots": [
    { "slot": 2, "slot_name": "Before-Save Flows", "components": ["Flow_Name_1"], "notes": "" },
    { "slot": 3, "slot_name": "Before Triggers", "components": ["JourneyTrigger → JourneyTriggerHandler → JourneyService.validateFields()"], "notes": "" },
    { "slot": 5, "slot_name": "Validation Rules", "components": ["VR_Journey_RequireStatus", "VR_Journey_DateRange"], "notes": "VR_DateRange has cross-object ref to Account" },
    { "slot": 7, "slot_name": "After Triggers", "components": ["JourneyTrigger → JourneyTriggerHandler → JourneyService.createRelatedRecords()"], "notes": "DML on JourneyStep__c — triggers cascade" },
    { "slot": 11, "slot_name": "After-Save Flows", "components": ["Journey_After_Save_Notification"], "notes": "Sends platform event" },
    { "slot": 16, "slot_name": "Async Operations", "components": ["JourneyNotificationQueueable"], "notes": "Enqueued by after trigger" }
  ]
}
```
→ `sf_architecture.order_of_operations[]`

B3 [GEN]: Note **execution ordering observations** (document facts, not judgments):
  - Multiple before-save flows on the same object — note that Salesforce executes them alphabetically by API name
  - Both a before trigger AND before-save flow exist on the same object — note which slots they occupy
  - After triggers AND after-save flows both perform DML on the same target object — document both paths
  - Validation rules that reference fields set by before triggers/flows — note the slot ordering

---

## Stream 2 [GEN] – Execution Chain Analysis
**Goal:** For each object's key DML events, trace the COMPLETE execution chain including all cascades — what actually happens from start to finish when a record is saved → `{{context_file}}.sf_architecture.execution_chains`

### Chain Tracing
C1 [GEN]: For each in-scope object, identify the most important DML events:
  - **Insert** — if triggers/flows fire on insert
  - **Update** — if triggers/flows fire on update (usually the most complex)
  - **Delete** — if triggers/flows fire on delete OR master-detail cascade delete exists

C2 [GEN]: For each object + event, trace the full chain step-by-step:

**Step format:** `{ step_number, slot_name, component, action, target_object, dml_type, note }`

Example chain for `Journey__c INSERT`:
```
Step 1: Before-Save Flow "Journey_Defaults" → sets default field values on Journey__c
Step 2: Before Trigger "JourneyTrigger" → JourneyTriggerHandler.beforeInsert() → JourneyService.validateFields() → validates business rules
Step 3: Validation Rule "VR_Journey_RequireStatus" → checks Status__c is not null
Step 4: After Trigger "JourneyTrigger" → JourneyTriggerHandler.afterInsert() → JourneyService.createSteps() → INSERT 3 JourneyStep__c records
  Step 4a: → CASCADE: JourneyStep__c INSERT fires JourneyStepTrigger → JourneyStepHandler.afterInsert() → (no further DML)
Step 5: After-Save Flow "Journey_Notification" → publishes Journey_Created__e platform event
Step 6: Roll-up on JourneyGroup__c recalculates TotalJourneys__c
  Step 6a: → CASCADE: JourneyGroup__c UPDATE fires JourneyGroupTrigger (if exists)
Step 7: [ASYNC] Platform event Journey_Created__e → subscribed by flow "Handle_Journey_Created"
Step 8: [ASYNC] JourneyNotificationQueueable → sends email notification
```

C3 [GEN]: For each chain, calculate:
  - `total_dml_count` — total DML statements in the synchronous transaction
  - `total_soql_count` — estimated SOQL queries (from Apex `soql_queries[]` in the chain)
  - `cascade_depth` — how many levels of cascaded DML (object A → B → C = depth 3)

### Output
C4 [GEN]: Store each chain:
```json
{
  "object": "Journey__c",
  "event": "insert",
  "chain_steps": [ /* step objects as above */ ],
  "async_forks": [ /* async operations triggered */ ],
  "total_dml_count": 5,
  "total_soql_count": 12,
  "cascade_depth": 2
}
```
→ `sf_architecture.execution_chains[]`

---

## Stream 3 [GEN] – Cross-Object Cascade Mapping
**Goal:** Trace how automation on one **{{scope.feature_area}}** object cascades to other objects — map the full ripple effect → `{{context_file}}.sf_architecture.cross_object_cascades`

### Cascade Discovery
D1 [GEN]: From execution chains (Stream 2), extract every DML operation that targets a DIFFERENT object:
  - After trigger DML (from `apex_classes[].dml_statements[]`)
  - After-save flow DML operations (from `flows[].dml_operations[]`)
  - Roll-up summary recalculations (from `sf_schema.relationships[]`)
  - Master-detail cascade deletes (from `sf_schema.relationships[]` where `is_cascade_delete = true`)

D2 [GEN]: For each cross-object DML, trace what happens on the TARGET object:
  - Does the target object have triggers? What fires?
  - Does the target object have flows? What runs?
  - Does the target object have validation rules that would execute?
  - Does the target object's automation cause further DML on a THIRD object?

### Cascade Path Construction
D3 [GEN]: Build complete cascade paths:
```
Journey__c INSERT
  → After Trigger inserts JourneyStep__c
    → JourneyStep__c After Trigger updates JourneyMilestone__c
      → JourneyMilestone__c rollup updates Journey__c (!! re-entrant)
```

D4 [GEN]: For each cascade path, assess:
  - `depth` — number of object hops (A → B → C = depth 3)
  - `re_entrant` — does the cascade path loop back to the originating object? (true/false)
  - `transaction_scope` — "synchronous" (all in same transaction) or "async_boundary" (breaks at platform event / queueable)
  - `failure_propagation` — if step N fails (e.g., validation rule on target object), does the entire transaction roll back?

### Re-Entrancy Documentation
D5 [GEN]: For re-entrant paths (cascade loops back to same object), document:
  - Whether Salesforce's built-in recursion guard applies (triggers run max 1 additional time in same transaction)
  - Whether the Apex code has explicit recursion guards (static boolean patterns, trigger framework bypass)
  - The re-entry mechanism (rollup summary, explicit DML, etc.)

### Transaction Boundary Mapping
D6 [GEN]: Identify where synchronous transaction ends and async begins:
  - Platform event publish → subscriber runs in separate transaction
  - Queueable enqueue → runs in separate transaction
  - Batch launch → runs in separate transactions per batch
  - Future method → runs in separate transaction
  - Note if the cascade mixes setup objects (User, Group) with non-setup objects in the same synchronous chain

### Output
D7 [GEN]: Store each cascade:
```json
{
  "trigger_object": "Journey__c",
  "trigger_event": "insert",
  "cascade_path": [
    { "step": 1, "source_object": "Journey__c", "source_component": "JourneyService.createSteps()", "target_object": "JourneyStep__c", "dml_type": "insert" },
    { "step": 2, "source_object": "JourneyStep__c", "source_component": "JourneyStepTrigger", "target_object": "JourneyMilestone__c", "dml_type": "update" },
    { "step": 3, "source_object": "JourneyMilestone__c", "source_component": "rollup_summary", "target_object": "Journey__c", "dml_type": "update" }
  ],
  "depth": 3,
  "re_entrant": true,
  "transaction_scope": "synchronous",
  "failure_propagation": "full_rollback"
}
```
→ `sf_architecture.cross_object_cascades[]`

---

## Stream 4 [GEN] – Transaction Boundary Mapping
**Goal:** Document transaction boundaries, synchronous vs async scoping, and mixed DML observations across **{{scope.feature_area}}** → `{{context_file}}.sf_architecture.transaction_analysis`

### Synchronous Transaction Boundaries
E1 [GEN]: For each execution chain (from Stream 2), identify everything that runs in the SAME synchronous transaction:
  - All before/after triggers + all before/after-save flows + all synchronous Apex
  - Aggregate: total DML count, total SOQL count per chain
  - Store: `{ chain_id, objects_touched[], total_sync_dml, total_sync_soql }`

### Async Boundaries
E2 [GEN]: Map async exit points and what runs in each async context:
  - Platform events → subscriber flows/triggers (separate transaction)
  - Queueable chains → each execute() is a separate transaction
  - Batch jobs → each execute() batch (up to 200 records) is a separate transaction
  - Scheduled flows → separate transaction
  - Store: `{ async_type, source_component, target_component, data_passed }`

### Mixed DML Observations
E3 [GEN]: Scan all synchronous chains for mixed DML:
  - Setup objects: User, Group, GroupMember, QueueSobject, UserRole, PermissionSet, PermissionSetAssignment
  - Document any chain that performs DML on both a setup object and a non-setup object in the same transaction
  - Note if the code uses `System.runAs()` or async deferral to separate them

### Shared State Documentation
E4 [GEN]: Document components that share state across the transaction:
  - Static variables used as recursion guards
  - Static collections used for cross-trigger communication
  - Custom metadata / custom settings read in multiple components (query vs cached?)
  - Platform cache usage

### Output
E5 [GEN]: Store:
```json
{
  "sync_boundaries": [ /* per-chain sync transaction summaries */ ],
  "async_boundaries": [ /* async exit points */ ],
  "mixed_dml_observations": [ /* any mixed DML findings */ ]
}
```
→ `sf_architecture.transaction_analysis`

---

## Stream 5 [GEN] – Component Layer Map & Narrative
**Goal:** Map discovered components into architectural layers and generate a factual narrative of how **{{scope.feature_area}}** works as a system → `{{context_file}}.sf_architecture.component_layer_map` + `.narrative`

### Component Layer Map
F1 [GEN]: Map the discovered components into architectural layers:
  - **UI Layer** — LWC components, Aura components, Visualforce pages
  - **Controller Layer** — Apex controllers (LWC controllers, Aura controllers)
  - **Service Layer** — Service classes containing business logic
  - **Domain Layer** — Domain classes, trigger handlers
  - **Selector Layer** — Selector/query classes
  - **Declarative Layer** — Flows (record-triggered, screen, scheduled), validation rules
  - **Integration Layer** — Callout classes, platform events, named credentials
  - **Data Layer** — Objects, fields, relationships (from Phase 03a)
  Store → `sf_architecture.component_layer_map`

### Narrative Generation
F2 [GEN]: Generate a factual, descriptive narrative:

**System Overview** (2–3 paragraphs):
  - "{{scope.feature_area}} is built on {{N}} objects with {{N}} automation components. The components are organized across [N] layers..."
  - Describe the primary execution flows in plain language
  - Describe how the layers connect (e.g., "UI components call controller Apex, which delegates to service classes, which query via selectors")

**Per-Object Summaries** (1 paragraph each):
  - For each in-scope object: "When a {{Object}} record is [created/updated], the following sequence executes: ..."
  - Focus on documenting what happens, step by step

Store → `sf_architecture.narrative`

---

## Completion [IO/GEN]
Update `{{context_file}}`:
- `metadata.phases_completed` append `"sf_architecture"`
- `metadata.current_phase` = `"sf_platform"`
- `metadata.last_updated` = ISO timestamp
- Write `sf_architecture.execution_summary`:
  - `max_cascade_depth` — deepest cascade chain across all objects
  - `re_entrant_cascade_count` — number of re-entrant cascade paths
  - `objects_with_mixed_automation` — count of objects with both triggers + record-triggered flows on same event
- Extend `synthesis.unified_truth` with:
  - `architecture_summary` — component layer map summary, execution chain count, cascade depth
  - `execution_summary` — same data as `sf_architecture.execution_summary` (convenience copy in synthesis)
- Append `{"phase":"sf_architecture","step":"complete","completedAt":"<ISO>","artifact":"{{context_file}}"}` to `run_state.completed_steps[]`
- Save to disk

Tell user: **"Execution model for {{scope.feature_area}} complete. Mapped order of operations for {{object_count}} objects across {{chain_count}} execution chains. Max cascade depth: {{max_depth}}. {{re_entrant_count}} re-entrant cascades. Components mapped across {{layer_count}} architectural layers. Use `/feature-research-phase-03d` for platform discovery."**

---

## Error Handling

| Scenario | Action |
|----------|--------|
| Context file missing | **STOP** — "Run `/feature-research-phase-01` first" |
| Phase 03b not completed | **STOP** — "Run `/feature-research-phase-03b` first" |
| No triggers or flows found for an object | Object has no custom automation; note as "data-only object" in narrative |
| Cannot determine execution order (ambiguous metadata) | Log assumption with reasoning; note in synthesis |
| Cascade depth exceeds 5 levels | Stop tracing at depth 5; note "deep cascade — traced to depth 5" |
| Cannot determine if Apex is bulkified (no source available) | Log assumption; note "bulk behavior not verified" |
| Mixed automation (trigger + flow on same event) | Document both; note Salesforce's documented execution order |
| Circular cascade detected | Document the cycle; note whether recursion guards exist |
